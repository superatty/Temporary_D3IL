_target_: agents.ddpm_agent.DDPM_Agent
_recursive_: false

model:
  _target_: agents.ddpm_agent.DDPM_Policy
  _recursive_: false

  visual_input: False
  device: ${device}

  model:
    _target_: agents.models.diffusion.gc_diffusion.Diffusion
    _recursive_: false

    state_dim: ${obs_dim}
    action_dim: ${action_dim}
    beta_schedule: "cosine"
    n_timesteps: 8
    loss_type: "l2"
    clip_denoised: true
    predict_epsilon: true
    device: ${device}
    diffusion_x: False
    diffusion_x_M: 10

    model:
      _target_: agents.models.diffusion.diffusion_models.DiffusionTransformerNetwork
      state_dim: ${obs_dim}
      action_dim: ${action_dim}
      goal_conditioned: False
      goal_seq_len: 10
      obs_seq_len: ${window_size}
      embed_pdrob: 0
      goal_drop: 0
      attn_pdrop: 0.2
      resid_pdrop: 0.1
      # Architecture details
      embed_dim: ${n_embd}
      n_layers: ${n_layer}
      n_heads: ${n_head}
      device: ${device}
      linear_output: true

  obs_encoder:
    _target_: torch.nn.Identity
    output_dim: ${obs_dim}

optimization:
  _target_: torch.optim.Adam
  lr: 5e-4 # for transformer
  weight_decay: 0

trainset: ${trainset}
valset: ${valset}
train_batch_size: ${train_batch_size}
val_batch_size: ${val_batch_size}
num_workers: ${num_workers}
epoch: ${epoch}
device: ${device}
scale_data: ${scale_data}
eval_every_n_epochs: ${eval_every_n_epochs}

discount: 0.99
use_ema: True
decay: 0.995
update_ema_every_n_steps: 1
goal_window_size: 1
window_size: ${window_size}
diffusion_kde: false
diffusion_kde_samples: 100
